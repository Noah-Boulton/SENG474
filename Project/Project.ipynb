{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "--\n",
    "In our ever changing and evolving field of technology one of the foremost topics is data analytics. The growth in the amount of digital data that is being collected across many different fields is massive and . That is, taking data in whatever raw form it exists and using technology to transform it into information that has value and context. In most cases data analysis is performed in order to provide class descriptions of data, highlight behaviors, trends, associations in the data or predictive information that prove useful or even vital to key decision-makers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection\n",
    "--\n",
    "Using the NHL API following the documentation found at https://gitlab.com/dword4/nhlapi/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each player in the specified year range (years must be consecutive) collect all avalible stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv_skaters(y1, y2):\n",
    "    team_rosters = requests.get('https://statsapi.web.nhl.com/api/v1/teams?expand=team.roster&season=' + y1 + y2)\n",
    "    team_rosters = team_rosters.json()\n",
    "    players= []\n",
    "    for i in range(0, len(team_rosters['teams'])):\n",
    "        for j in range(0, len(team_rosters['teams'][i]['roster']['roster'])):\n",
    "            player = [team_rosters['teams'][i]['roster']['roster'][j]['person']['id'], \n",
    "                      team_rosters['teams'][i]['roster']['roster'][j]['person']['fullName'],\n",
    "                     team_rosters['teams'][i]['name']]\n",
    "            if (team_rosters['teams'][i]['roster']['roster'][j]['position']['code'] != 'G'):\n",
    "                players.append(player)\n",
    "    players_stats = []\n",
    "    labels = requests.get('https://statsapi.web.nhl.com/api/v1/people/' \n",
    "                           + str(players[i][0]) \n",
    "                           + '/stats?stats=statsSingleSeason&season=' + y1 + y2).json()\n",
    "    labels = labels['stats'][0]['splits'][0]['stat']\n",
    "    header = ['id', 'fullName', 'teamName']\n",
    "    for label in labels:\n",
    "        header.append(label)\n",
    "    for i in range(0, len(players)): \n",
    "        stats = requests.get('https://statsapi.web.nhl.com/api/v1/people/' \n",
    "                           + str(players[i][0]) \n",
    "                           + '/stats?stats=statsSingleSeason&season=' + y1 + y2).json()\n",
    "        if(stats['stats'][0]['splits'] == []):\n",
    "            players_stats.append([0] * len(labels))\n",
    "            continue\n",
    "        stats = stats['stats'][0]['splits'][0]['stat']\n",
    "        stats_array = []\n",
    "        for label in labels:\n",
    "            if label in stats:\n",
    "                stats_array.append(stats[label])\n",
    "            else:\n",
    "                stats_array.append(0)\n",
    "        players_stats.append(stats_array)\n",
    "        \n",
    "    skaters = []\n",
    "    skaters.append(header)\n",
    "    for i in range(0, len(players)):\n",
    "        skaters.append(players[i] + players_stats[i])\n",
    "    return skaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the skaters data for a year range and saves the result as a csv file.\n",
    "Years must be in the range [1917, 2019], note that the 2004-2005 season is skipped as this was a lockout year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_skaters_data(start, end):\n",
    "    for i in range(start, end):\n",
    "        if(i == 2004):\n",
    "            continue\n",
    "        print(\"Getting skaters data for \" + str(i) + \"-\" + str(i+1) + \" season.\")\n",
    "        skaters = get_csv_skaters(str(i), str(i+1))\n",
    "        np.savetxt('data/skaters_' + str(i) + '_' + str(i+1) + '.csv', skaters, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_skaters_data(1917,1918)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For each team in the specified year range (years must be consecutive) collect all avalible stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv_team(y1, y2):\n",
    "    teams = requests.get('https://statsapi.web.nhl.com/api/v1/teams?season=' + str(y1) + str(y2))\n",
    "    teams = teams.json()\n",
    "    team_id_name = []\n",
    "    for i in range(0, len(teams['teams'])):\n",
    "        team_arr = [teams['teams'][i]['id'], teams['teams'][i]['name']]\n",
    "        team_id_name.append(team_arr)\n",
    "\n",
    "    labels = requests.get('https://statsapi.web.nhl.com/api/v1/teams/' \n",
    "                           + str(team_id_name[0][0])\n",
    "                           + '/stats?stats=statsSingleSeason&season=' + str(y1) + str(y2)).json()\n",
    "    labels = labels['stats'][0]['splits'][0]['stat']\n",
    "    \n",
    "    header = ['id', 'teamName']\n",
    "    for label in labels:\n",
    "        header.append(label)\n",
    "    header.append('PDO')\n",
    "    team_stats = []\n",
    "    for i in range(0, len(team_id_name)):\n",
    "        stats = requests.get('https://statsapi.web.nhl.com/api/v1/teams/' \n",
    "                             + str(team_id_name[i][0]) \n",
    "                             + '/stats?stats=statsSingleSeason&season=' + str(y1) + str(y2)).json()\n",
    "        if(stats['stats'][0]['splits'] == []):\n",
    "            team_stats.append([0] * len(labels))\n",
    "            continue\n",
    "        stats = stats['stats'][0]['splits'][0]['stat']\n",
    "        stats_array = []\n",
    "        for label in labels:\n",
    "            if label in stats:\n",
    "                stats_array.append(stats[label])\n",
    "            else:\n",
    "                stats_array.append(0)\n",
    "        team_stats.append(stats_array)\n",
    "        stats_array.append((stats['shootingPctg']/100) + stats['savePctg'])\n",
    "    \n",
    "    teams_stats_final = []\n",
    "    teams_stats_final.append(header)\n",
    "    for i in range(0, len(team_id_name)):\n",
    "        teams_stats_final.append(team_id_name[i] + team_stats[i]) \n",
    "    return teams_stats_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the team data for a year range and saves the result as a csv file.\n",
    "Years must be in the range [1917, 2019], note that the 2004-2005 season is skipped as this was a lockout year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_team_data(start, end):\n",
    "    for i in range(start, end):\n",
    "        if(i == 2004):\n",
    "            continue\n",
    "        print(\"Getting team data for \" + str(i) + \"-\" + str(i+1) + \" season.\")\n",
    "        data = get_csv_team(str(i), str(i+1))\n",
    "        np.savetxt('team_data/teams_' + str(i) + '_' + str(i+1) + '.csv', data, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting team data for 2000-2001 season.\n",
      "Getting team data for 2001-2002 season.\n",
      "Getting team data for 2002-2003 season.\n",
      "Getting team data for 2003-2004 season.\n",
      "Getting team data for 2005-2006 season.\n",
      "Getting team data for 2006-2007 season.\n",
      "Getting team data for 2007-2008 season.\n",
      "Getting team data for 2008-2009 season.\n",
      "Getting team data for 2009-2010 season.\n",
      "Getting team data for 2010-2011 season.\n",
      "Getting team data for 2011-2012 season.\n",
      "Getting team data for 2012-2013 season.\n",
      "Getting team data for 2013-2014 season.\n",
      "Getting team data for 2014-2015 season.\n",
      "Getting team data for 2015-2016 season.\n",
      "Getting team data for 2016-2017 season.\n",
      "Getting team data for 2017-2018 season.\n"
     ]
    }
   ],
   "source": [
    "get_team_data(2000, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the index of the team stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_team_stats(id, team_data):\n",
    "    for i in range(0, len(team_data)):\n",
    "        if team_data[i][0] == id:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each game in the specified year range (years must be consecutive) return the winner, away team ID, home team ID, and the away and home team stats for that season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv_game(y1, y2):\n",
    "    team_data = get_csv_team(y1, y2)\n",
    "    header = team_data[0][3:]\n",
    "    away_header = []\n",
    "    home_header = []\n",
    "    for head in header:\n",
    "        away_header.append('away_'+head)\n",
    "        home_header.append('home_'+head)\n",
    "    games_data = [['winner', 'awayID', 'homeID'] + away_header + home_header]\n",
    "    games = requests.get('https://statsapi.web.nhl.com/api/v1/schedule?startDate=' \n",
    "                         + str(y1) + '-10-01&endDate=' + str(y2) + '-06-30')\n",
    "    games = games.json()\n",
    "    for date in games['dates']:\n",
    "        for game in date['games']:\n",
    "            away_ID = game['teams']['away']['team']['id']\n",
    "            home_ID = game['teams']['home']['team']['id']\n",
    "            if away_ID > 80 or home_ID > 80:\n",
    "                continue\n",
    "            \n",
    "            away_score = game['teams']['away']['score']\n",
    "            home_score = game['teams']['home']['score']\n",
    "            winner = 0\n",
    "            away_stats = team_data[get_team_stats(away_ID, team_data)][3:]\n",
    "            home_stats = team_data[get_team_stats(home_ID, team_data)][3:]\n",
    "            if home_score > away_score:\n",
    "                winner = 1\n",
    "            games_data.append([winner,\n",
    "                          away_ID, \n",
    "                          home_ID] +\n",
    "                          away_stats +\n",
    "                          home_stats)\n",
    "    return games_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the game data for a year range and saves the result as a csv file.\n",
    "Years must be in the range [1917, 2019], note that the 2004-2005 season is skipped as this was a lockout year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_game_data(start, end):\n",
    "    for i in range(start, end):\n",
    "        if(i == 2004):\n",
    "            continue\n",
    "        print(\"Getting game data for \" + str(i) + \"-\" + str(i+1) + \" season.\")\n",
    "        data = get_csv_game(i, i+1)\n",
    "        np.savetxt('game_data/game_data_' + str(i) + '_' + str(i+1) + '.csv', data, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting game data for 2000-2001 season.\n",
      "Getting game data for 2001-2002 season.\n",
      "Getting game data for 2002-2003 season.\n",
      "Getting game data for 2003-2004 season.\n",
      "Getting game data for 2005-2006 season.\n",
      "Getting game data for 2006-2007 season.\n",
      "Getting game data for 2007-2008 season.\n",
      "Getting game data for 2008-2009 season.\n",
      "Getting game data for 2009-2010 season.\n",
      "Getting game data for 2010-2011 season.\n",
      "Getting game data for 2011-2012 season.\n",
      "Getting game data for 2012-2013 season.\n",
      "Getting game data for 2013-2014 season.\n",
      "Getting game data for 2014-2015 season.\n",
      "Getting game data for 2015-2016 season.\n",
      "Getting game data for 2016-2017 season.\n",
      "Getting game data for 2017-2018 season.\n"
     ]
    }
   ],
   "source": [
    "get_game_data(2000,2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup master csv and normalized master csv file of all the games data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000_2001 = pd.read_csv('game_data/game_data_2000_2001.csv', header=0)\n",
    "data_2001_2002 = pd.read_csv('game_data/game_data_2001_2002.csv', header=0)\n",
    "data_2002_2003 = pd.read_csv('game_data/game_data_2002_2003.csv', header=0)\n",
    "data_2003_2004 = pd.read_csv('game_data/game_data_2003_2004.csv', header=0)\n",
    "data_2005_2006 = pd.read_csv('game_data/game_data_2005_2006.csv', header=0)\n",
    "data_2006_2007 = pd.read_csv('game_data/game_data_2006_2007.csv', header=0)\n",
    "data_2007_2008 = pd.read_csv('game_data/game_data_2007_2008.csv', header=0)\n",
    "data_2008_2009 = pd.read_csv('game_data/game_data_2008_2009.csv', header=0)\n",
    "data_2009_2010 = pd.read_csv('game_data/game_data_2009_2010.csv', header=0)\n",
    "data_2010_2011 = pd.read_csv('game_data/game_data_2010_2011.csv', header=0)\n",
    "data_2011_2012 = pd.read_csv('game_data/game_data_2011_2012.csv', header=0)\n",
    "data_2012_2013 = pd.read_csv('game_data/game_data_2012_2013.csv', header=0)\n",
    "data_2013_2014 = pd.read_csv('game_data/game_data_2013_2014.csv', header=0)\n",
    "data_2014_2015 = pd.read_csv('game_data/game_data_2014_2015.csv', header=0)\n",
    "data_2015_2016 = pd.read_csv('game_data/game_data_2015_2016.csv', header=0)\n",
    "data_2016_2017 = pd.read_csv('game_data/game_data_2016_2017.csv', header=0)\n",
    "data_2017_2018 = pd.read_csv('game_data/game_data_2017_2018.csv', header=0)\n",
    "\n",
    "frames = [data_2000_2001, data_2001_2002, data_2002_2003, data_2003_2004, data_2005_2006, \n",
    "          data_2006_2007, data_2007_2008, data_2008_2009, data_2009_2010, data_2010_2011, \n",
    "          data_2011_2012, data_2012_2013, data_2013_2014, data_2014_2015, data_2015_2016, \n",
    "          data_2016_2017, data_2017_2018]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "\n",
    "data = data.drop(['away_wins', 'away_losses', 'away_ot',\n",
    "       'away_pts', 'away_ptPctg', 'away_powerPlayGoals',\n",
    "       'away_powerPlayGoalsAgainst', 'away_powerPlayOpportunities','away_shotsPerGame', 'away_shotsAllowed',\n",
    "       'away_winScoreFirst', 'away_winOppScoreFirst', 'away_winLeadFirstPer',\n",
    "       'away_winLeadSecondPer', 'away_winOutshootOpp', 'away_winOutshotByOpp',\n",
    "       'away_faceOffsTaken', 'away_faceOffsWon', 'away_faceOffsLost',\n",
    "       'away_faceOffWinPercentage',\n",
    "       'home_wins', 'home_losses', 'home_ot',\n",
    "       'home_pts', 'home_ptPctg', 'home_powerPlayGoals',\n",
    "       'home_powerPlayGoalsAgainst', 'home_powerPlayOpportunities','home_shotsPerGame', 'home_shotsAllowed',\n",
    "       'home_winScoreFirst', 'home_winOppScoreFirst', 'home_winLeadFirstPer',\n",
    "       'home_winLeadSecondPer', 'home_winOutshootOpp', 'home_winOutshotByOpp',\n",
    "       'home_faceOffsTaken', 'home_faceOffsWon', 'home_faceOffsLost',\n",
    "       'home_faceOffWinPercentage'], axis=1)\n",
    "header = ['winner', 'awayID', 'homeID', 'away_goalsPerGame',\n",
    "       'away_goalsAgainstPerGame', 'away_evGGARatio',\n",
    "       'away_powerPlayPercentage', 'away_penaltyKillPercentage',\n",
    "       'away_shootingPctg', 'away_savePctg', 'away_PDO', 'home_goalsPerGame',\n",
    "       'home_goalsAgainstPerGame', 'home_evGGARatio',\n",
    "       'home_powerPlayPercentage', 'home_penaltyKillPercentage',\n",
    "       'home_shootingPctg', 'home_savePctg', 'home_PDO']\n",
    "header = ','.join(header)\n",
    "\n",
    "np.savetxt('master.csv', data, fmt='%s', delimiter=',', header = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    max_data = np.max(data, axis=0)\n",
    "    min_data = np.min(data, axis=0)\n",
    "    stats = ['away_wins', 'away_losses', 'away_ot',\n",
    "             'away_pts', 'away_ptPctg', 'away_goalsPerGame',\n",
    "             'away_goalsAgainstPerGame', 'away_evGGARatio',\n",
    "             'away_powerPlayPercentage', 'away_powerPlayGoals',\n",
    "             'away_powerPlayGoalsAgainst', 'away_powerPlayOpportunities',\n",
    "             'away_penaltyKillPercentage', 'away_shotsPerGame', 'away_shotsAllowed',\n",
    "             'away_winScoreFirst', 'away_winOppScoreFirst', 'away_winLeadFirstPer',\n",
    "             'away_winLeadSecondPer', 'away_winOutshootOpp', 'away_winOutshotByOpp',\n",
    "             'away_faceOffsTaken', 'away_faceOffsWon', 'away_faceOffsLost',\n",
    "             'away_faceOffWinPercentage', 'away_shootingPctg', 'away_savePctg',\n",
    "             'home_wins', 'home_losses', 'home_ot', 'home_pts', 'home_ptPctg',\n",
    "             'home_goalsPerGame', 'home_goalsAgainstPerGame', 'home_evGGARatio',\n",
    "             'home_powerPlayPercentage', 'home_powerPlayGoals',\n",
    "             'home_powerPlayGoalsAgainst', 'home_powerPlayOpportunities',\n",
    "             'home_penaltyKillPercentage', 'home_shotsPerGame', 'home_shotsAllowed',\n",
    "             'home_winScoreFirst', 'home_winOppScoreFirst', 'home_winLeadFirstPer',\n",
    "             'home_winLeadSecondPer', 'home_winOutshootOpp', 'home_winOutshotByOpp',\n",
    "             'home_faceOffsTaken', 'home_faceOffsWon', 'home_faceOffsLost',\n",
    "             'home_faceOffWinPercentage', 'home_shootingPctg', 'home_savePctg']\n",
    "    for stat in stats:\n",
    "        data[stat] = (data[stat] - min_data[stat])/(max_data[stat] - min_data[stat])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000_2001 = pd.read_csv('game_data/game_data_2000_2001.csv', header=0)\n",
    "data_2001_2002 = pd.read_csv('game_data/game_data_2001_2002.csv', header=0)\n",
    "data_2002_2003 = pd.read_csv('game_data/game_data_2002_2003.csv', header=0)\n",
    "data_2003_2004 = pd.read_csv('game_data/game_data_2003_2004.csv', header=0)\n",
    "data_2005_2006 = pd.read_csv('game_data/game_data_2005_2006.csv', header=0)\n",
    "data_2006_2007 = pd.read_csv('game_data/game_data_2006_2007.csv', header=0)\n",
    "data_2007_2008 = pd.read_csv('game_data/game_data_2007_2008.csv', header=0)\n",
    "data_2008_2009 = pd.read_csv('game_data/game_data_2008_2009.csv', header=0)\n",
    "data_2009_2010 = pd.read_csv('game_data/game_data_2009_2010.csv', header=0)\n",
    "data_2010_2011 = pd.read_csv('game_data/game_data_2010_2011.csv', header=0)\n",
    "data_2011_2012 = pd.read_csv('game_data/game_data_2011_2012.csv', header=0)\n",
    "data_2012_2013 = pd.read_csv('game_data/game_data_2012_2013.csv', header=0)\n",
    "data_2013_2014 = pd.read_csv('game_data/game_data_2013_2014.csv', header=0)\n",
    "data_2014_2015 = pd.read_csv('game_data/game_data_2014_2015.csv', header=0)\n",
    "data_2015_2016 = pd.read_csv('game_data/game_data_2015_2016.csv', header=0)\n",
    "data_2016_2017 = pd.read_csv('game_data/game_data_2016_2017.csv', header=0)\n",
    "data_2017_2018 = pd.read_csv('game_data/game_data_2017_2018.csv', header=0)\n",
    "\n",
    "data_2000_2001 = normalize(data_2000_2001)\n",
    "data_2001_2002 = normalize(data_2001_2002)\n",
    "data_2002_2003 = normalize(data_2002_2003)\n",
    "data_2003_2004 = normalize(data_2003_2004)\n",
    "data_2005_2006 = normalize(data_2005_2006)\n",
    "data_2006_2007 = normalize(data_2006_2007)\n",
    "data_2007_2008 = normalize(data_2007_2008)\n",
    "data_2008_2009 = normalize(data_2008_2009)\n",
    "data_2009_2010 = normalize(data_2009_2010)\n",
    "data_2010_2011 = normalize(data_2010_2011)\n",
    "data_2011_2012 = normalize(data_2011_2012)\n",
    "data_2012_2013 = normalize(data_2012_2013)\n",
    "data_2013_2014 = normalize(data_2013_2014)\n",
    "data_2014_2015 = normalize(data_2014_2015)\n",
    "data_2016_2017 = normalize(data_2016_2017)\n",
    "data_2017_2018 = normalize(data_2017_2018)\n",
    "\n",
    "frames = [data_2000_2001, data_2001_2002, data_2002_2003, data_2003_2004, data_2005_2006, \n",
    "          data_2006_2007, data_2007_2008, data_2008_2009, data_2009_2010, data_2010_2011, \n",
    "          data_2011_2012, data_2012_2013, data_2013_2014, data_2014_2015, data_2015_2016, \n",
    "          data_2016_2017, data_2017_2018]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "\n",
    "data = data.drop(['away_wins', 'away_losses', 'away_ot',\n",
    "       'away_pts', 'away_ptPctg', 'away_powerPlayGoals',\n",
    "       'away_powerPlayGoalsAgainst', 'away_powerPlayOpportunities','away_shotsPerGame', 'away_shotsAllowed',\n",
    "       'away_winScoreFirst', 'away_winOppScoreFirst', 'away_winLeadFirstPer',\n",
    "       'away_winLeadSecondPer', 'away_winOutshootOpp', 'away_winOutshotByOpp',\n",
    "       'away_faceOffsTaken', 'away_faceOffsWon', 'away_faceOffsLost',\n",
    "       'away_faceOffWinPercentage',\n",
    "       'home_wins', 'home_losses', 'home_ot',\n",
    "       'home_pts', 'home_ptPctg', 'home_powerPlayGoals',\n",
    "       'home_powerPlayGoalsAgainst', 'home_powerPlayOpportunities','home_shotsPerGame', 'home_shotsAllowed',\n",
    "       'home_winScoreFirst', 'home_winOppScoreFirst', 'home_winLeadFirstPer',\n",
    "       'home_winLeadSecondPer', 'home_winOutshootOpp', 'home_winOutshotByOpp',\n",
    "       'home_faceOffsTaken', 'home_faceOffsWon', 'home_faceOffsLost',\n",
    "       'home_faceOffWinPercentage'], axis=1)\n",
    "header = ['winner', 'awayID', 'homeID', 'away_goalsPerGame',\n",
    "       'away_goalsAgainstPerGame', 'away_evGGARatio',\n",
    "       'away_powerPlayPercentage', 'away_penaltyKillPercentage',\n",
    "       'away_shootingPctg', 'away_savePctg', 'away_PDO', 'home_goalsPerGame',\n",
    "       'home_goalsAgainstPerGame', 'home_evGGARatio',\n",
    "       'home_powerPlayPercentage', 'home_penaltyKillPercentage',\n",
    "       'home_shootingPctg', 'home_savePctg', 'home_PDO']\n",
    "header = ','.join(header)\n",
    "\n",
    "np.savetxt('master_normalized.csv', data, fmt='%s', delimiter=',', header = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aanaylsis\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    X = data.iloc[:,3:].values\n",
    "    # we insert an all-ones column at index 0\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    # get the first column of the data\n",
    "    y = data.iloc[:,0:1].values\n",
    "    return X,y\n",
    "\n",
    "def split_train_test(X,y,pct=80):\n",
    "    n = X.shape[0]\n",
    "    s = round(n * pct / 100)\n",
    "    \n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, test_idx = indices[:s], indices[s:]\n",
    "    \n",
    "    X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "    y_train, y_test = y[train_idx,:], y[test_idx,:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def accuracy(pred, labels):\n",
    "    count = 0\n",
    "    for i in range(0, len(pred)):\n",
    "        if(pred[i] == labels[i]):\n",
    "            count += 1\n",
    "    return count/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM using various kernals\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('master_normalized.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = prepare(data)\n",
    "\n",
    "X,Y,X_test,Y_test = split_train_test(X,y,pct=80)\n",
    "Y = np.concatenate(Y, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>awayID</th>\n",
       "      <th>homeID</th>\n",
       "      <th>away_goalsPerGame</th>\n",
       "      <th>away_goalsAgainstPerGame</th>\n",
       "      <th>away_evGGARatio</th>\n",
       "      <th>away_powerPlayPercentage</th>\n",
       "      <th>away_penaltyKillPercentage</th>\n",
       "      <th>away_shootingPctg</th>\n",
       "      <th>away_savePctg</th>\n",
       "      <th>away_PDO</th>\n",
       "      <th>home_goalsPerGame</th>\n",
       "      <th>home_goalsAgainstPerGame</th>\n",
       "      <th>home_evGGARatio</th>\n",
       "      <th>home_powerPlayPercentage</th>\n",
       "      <th>home_penaltyKillPercentage</th>\n",
       "      <th>home_shootingPctg</th>\n",
       "      <th>home_savePctg</th>\n",
       "      <th>home_PDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0.803099</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.574564</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.620057</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>0.734781</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.464170</td>\n",
       "      <td>0.613302</td>\n",
       "      <td>0.795786</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.330536</td>\n",
       "      <td>0.584687</td>\n",
       "      <td>0.664542</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.393802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559070</td>\n",
       "      <td>0.508894</td>\n",
       "      <td>0.767300</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.566817</td>\n",
       "      <td>0.216551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>0.668819</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>0.849896</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.490333</td>\n",
       "      <td>0.444459</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner  awayID  homeID  away_goalsPerGame  away_goalsAgainstPerGame  \\\n",
       "0       0      21      25           0.803099                  0.075019   \n",
       "1       0       9       6           0.834087                  0.197989   \n",
       "2       1      16       7           0.330536                  0.584687   \n",
       "3       1      23       4           0.559070                  0.508894   \n",
       "4       0      17      20           0.668819                  0.169374   \n",
       "\n",
       "   away_evGGARatio  away_powerPlayPercentage  away_penaltyKillPercentage  \\\n",
       "0         0.789802                  0.932331                    0.475248   \n",
       "1         0.734781                  0.676692                    0.841584   \n",
       "2         0.664542                  0.248120                    0.594059   \n",
       "3         0.767300                  0.563910                    0.287129   \n",
       "4         0.849896                  0.939850                    0.772277   \n",
       "\n",
       "   away_shootingPctg  away_savePctg  away_PDO  home_goalsPerGame  \\\n",
       "0           0.885714       0.700000     1.020           0.574564   \n",
       "1           0.828571       0.733333     1.019           0.464170   \n",
       "2           0.428571       0.066667     0.985           0.393802   \n",
       "3           0.457143       0.066667     0.986           0.566817   \n",
       "4           0.371429       0.766667     1.004           0.227889   \n",
       "\n",
       "   home_goalsAgainstPerGame  home_evGGARatio  home_powerPlayPercentage  \\\n",
       "0                  0.027842         0.620057                  0.751880   \n",
       "1                  0.613302         0.795786                  0.511278   \n",
       "2                  0.000000         0.502732                  0.488722   \n",
       "3                  0.216551         1.000000                  0.458647   \n",
       "4                  0.490333         0.444459                  0.398496   \n",
       "\n",
       "   home_penaltyKillPercentage  home_shootingPctg  home_savePctg  home_PDO  \n",
       "0                    0.821782           0.942857       0.733333     1.023  \n",
       "1                    0.475248           0.400000       0.000000     0.982  \n",
       "2                    1.000000           0.485714       1.000000     1.015  \n",
       "3                    0.445545           0.457143       0.566667     1.001  \n",
       "4                    0.188119           0.171429       0.266667     0.982  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_svc = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_Y_pred = linear_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_acc = accuracy(linear_Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590867992766727\n"
     ]
    }
   ],
   "source": [
    "print(lin_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 930 1173]\n",
      " [ 637 1684]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.44      0.51      2103\n",
      "          1       0.59      0.73      0.65      2321\n",
      "\n",
      "avg / total       0.59      0.59      0.58      4424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, linear_Y_pred))  \n",
    "print(classification_report(Y_test, linear_Y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial SVC - degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_svc = svm.SVC(kernel='poly', degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_Y_pred = poly_svc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_acc = accuracy(poly_Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5924502712477396\n"
     ]
    }
   ],
   "source": [
    "print(poly_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 695 1408]\n",
      " [ 395 1926]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.33      0.44      2103\n",
      "          1       0.58      0.83      0.68      2321\n",
      "\n",
      "avg / total       0.61      0.59      0.56      4424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, poly_Y_pred))  \n",
    "print(classification_report(Y_test, poly_Y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_svc = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_svc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_Y_pred = gaussian_svc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_acc = accuracy(gaussian_Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5881555153707052\n"
     ]
    }
   ],
   "source": [
    "print(gaussian_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 695 1408]\n",
      " [ 395 1926]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.33      0.44      2103\n",
      "          1       0.58      0.83      0.68      2321\n",
      "\n",
      "avg / total       0.61      0.59      0.56      4424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, poly_Y_pred))  \n",
    "print(classification_report(Y_test, poly_Y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid_svc = svm.SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_svc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid_Y_pred = sigmoid_svc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid_acc = accuracy(sigmoid_Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5339059674502713\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1022 1081]\n",
      " [ 981 1340]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.49      0.50      2103\n",
      "          1       0.55      0.58      0.57      2321\n",
      "\n",
      "avg / total       0.53      0.53      0.53      4424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, sigmoid_Y_pred))  \n",
    "print(classification_report(Y_test, sigmoid_Y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensamble Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensamble(pred1, pred2, pred3, pred4):\n",
    "    prediction = []\n",
    "    for i in range(0, len(pred1)):\n",
    "        p = (pred1[i] + pred2[i] + pred3[i] + pred4[i])\n",
    "        p = p/4\n",
    "        if(p < 0.5):\n",
    "            prediction.append(0)\n",
    "        else:\n",
    "            prediction.append(1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensamble_pred = ensamble(linear_Y_pred, poly_Y_pred, gaussian_Y_pred, sigmoid_Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594258589511754\n"
     ]
    }
   ],
   "source": [
    "ensamble_acc = accuracy(ensamble_pred, Y_test)\n",
    "\n",
    "print(ensamble_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Logistic regression in TensorFlow\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('master_normalized.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = prepare(data)\n",
    "\n",
    "X,Y,X_test,Y_test = split_train_test(X,y,pct=80)\n",
    "Y = np.concatenate(Y, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>awayID</th>\n",
       "      <th>homeID</th>\n",
       "      <th>away_goalsPerGame</th>\n",
       "      <th>away_goalsAgainstPerGame</th>\n",
       "      <th>away_evGGARatio</th>\n",
       "      <th>away_powerPlayPercentage</th>\n",
       "      <th>away_penaltyKillPercentage</th>\n",
       "      <th>away_shootingPctg</th>\n",
       "      <th>away_savePctg</th>\n",
       "      <th>away_PDO</th>\n",
       "      <th>home_goalsPerGame</th>\n",
       "      <th>home_goalsAgainstPerGame</th>\n",
       "      <th>home_evGGARatio</th>\n",
       "      <th>home_powerPlayPercentage</th>\n",
       "      <th>home_penaltyKillPercentage</th>\n",
       "      <th>home_shootingPctg</th>\n",
       "      <th>home_savePctg</th>\n",
       "      <th>home_PDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0.803099</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.574564</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.620057</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>0.734781</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.464170</td>\n",
       "      <td>0.613302</td>\n",
       "      <td>0.795786</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.330536</td>\n",
       "      <td>0.584687</td>\n",
       "      <td>0.664542</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.393802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559070</td>\n",
       "      <td>0.508894</td>\n",
       "      <td>0.767300</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.566817</td>\n",
       "      <td>0.216551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>0.668819</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>0.849896</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.490333</td>\n",
       "      <td>0.444459</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner  awayID  homeID  away_goalsPerGame  away_goalsAgainstPerGame  \\\n",
       "0       0      21      25           0.803099                  0.075019   \n",
       "1       0       9       6           0.834087                  0.197989   \n",
       "2       1      16       7           0.330536                  0.584687   \n",
       "3       1      23       4           0.559070                  0.508894   \n",
       "4       0      17      20           0.668819                  0.169374   \n",
       "\n",
       "   away_evGGARatio  away_powerPlayPercentage  away_penaltyKillPercentage  \\\n",
       "0         0.789802                  0.932331                    0.475248   \n",
       "1         0.734781                  0.676692                    0.841584   \n",
       "2         0.664542                  0.248120                    0.594059   \n",
       "3         0.767300                  0.563910                    0.287129   \n",
       "4         0.849896                  0.939850                    0.772277   \n",
       "\n",
       "   away_shootingPctg  away_savePctg  away_PDO  home_goalsPerGame  \\\n",
       "0           0.885714       0.700000     1.020           0.574564   \n",
       "1           0.828571       0.733333     1.019           0.464170   \n",
       "2           0.428571       0.066667     0.985           0.393802   \n",
       "3           0.457143       0.066667     0.986           0.566817   \n",
       "4           0.371429       0.766667     1.004           0.227889   \n",
       "\n",
       "   home_goalsAgainstPerGame  home_evGGARatio  home_powerPlayPercentage  \\\n",
       "0                  0.027842         0.620057                  0.751880   \n",
       "1                  0.613302         0.795786                  0.511278   \n",
       "2                  0.000000         0.502732                  0.488722   \n",
       "3                  0.216551         1.000000                  0.458647   \n",
       "4                  0.490333         0.444459                  0.398496   \n",
       "\n",
       "   home_penaltyKillPercentage  home_shootingPctg  home_savePctg  home_PDO  \n",
       "0                    0.821782           0.942857       0.733333     1.023  \n",
       "1                    0.475248           0.400000       0.000000     0.982  \n",
       "2                    1.000000           0.485714       1.000000     1.015  \n",
       "3                    0.445545           0.457143       0.566667     1.001  \n",
       "4                    0.188119           0.171429       0.266667     0.982  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape (17698, 17) (17698, 1)\n",
      "Test dataset shape (4424, 17) (4424, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.reshape((Y.shape[0],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],1))\n",
    "\n",
    "print(\"Train dataset shape\", X.shape, Y.shape)\n",
    "print(\"Test dataset shape\", X_test.shape, Y_test.shape)\n",
    "\n",
    "m   = X.shape[0] \n",
    "n_x = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(A, Y):\n",
    "    P = A>.5      #prediction\n",
    "    num_agreements = np.sum(P==Y)\n",
    "    return num_agreements / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data.\n",
    "# Load the training and test data into constants\n",
    "tf_X = tf.constant(X.astype(np.float32))\n",
    "tf_Y = tf.constant(Y.astype(np.float32))\n",
    "tf_X_test = tf.constant(X_test.astype(np.float32))\n",
    "tf_Y_test = tf.constant(Y_test.astype(np.float32))\n",
    "\n",
    "# Variables.\n",
    "# These are the parameters that we are going to be training.\n",
    "tf_w = tf.Variable(tf.zeros((n_x, 1)))\n",
    "tf_b = tf.Variable(tf.zeros((1,1)))\n",
    "\n",
    "# Training computation.\n",
    "# We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "# the sigmoid and cross-entropy (it's one operation in TensorFlow, because\n",
    "# it's very common, and it can be optimized). We take the average of this\n",
    "# cross-entropy across all training examples: that's our cost.\n",
    "tf_Z = tf.matmul(tf_X, tf_w) + tf_b\n",
    "tf_J = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_Y, logits=tf_Z) )\n",
    "\n",
    "# Optimizer.\n",
    "# We are going to find the minimum of this loss using gradient descent.\n",
    "# We pass alpha=0.1 as input parameter.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(tf_J)\n",
    "\n",
    "# Predictions for the train and test data.\n",
    "# These are not part of training, but merely here so that we can report\n",
    "# accuracy figures as we train.\n",
    "tf_A = tf.nn.sigmoid(tf_Z)\n",
    "tf_A_test = tf.nn.sigmoid(tf.matmul(tf_X_test, tf_w) + tf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0 0.693131\n",
      "1 0.746797\n",
      "2 1.75275\n",
      "3 1.03357\n",
      "4 1.51833\n",
      "5 1.22138\n",
      "6 1.30908\n",
      "7 1.39474\n",
      "8 1.11621\n",
      "9 1.55757\n",
      "10 0.934253\n",
      "11 1.71249\n",
      "12 0.761854\n",
      "13 1.78962\n",
      "14 0.693884\n",
      "15 1.14816\n",
      "16 1.37988\n",
      "17 1.33583\n",
      "18 1.17094\n",
      "19 1.50904\n",
      "20 0.97843\n",
      "21 1.67161\n",
      "22 0.797491\n",
      "23 1.80393\n",
      "24 0.686385\n",
      "25 0.806689\n",
      "26 1.75353\n",
      "27 1.01832\n",
      "28 1.52315\n",
      "29 1.20415\n",
      "30 1.31649\n",
      "31 1.37612\n",
      "32 1.1253\n",
      "33 1.53802\n",
      "34 0.944447\n",
      "35 1.69247\n",
      "36 0.771973\n",
      "37 1.79606\n",
      "38 0.68476\n",
      "39 0.936593\n",
      "40 1.60741\n",
      "41 1.13357\n",
      "42 1.38709\n",
      "43 1.31379\n",
      "44 1.18701\n",
      "45 1.48165\n",
      "46 1.00025\n",
      "47 1.64055\n",
      "48 0.822701\n",
      "49 1.78389\n",
      "50 0.686224\n",
      "51 1.10835\n",
      "52 1.40818\n",
      "53 1.29663\n",
      "54 1.19878\n",
      "55 1.47037\n",
      "56 1.00595\n",
      "57 1.63348\n",
      "58 0.82436\n",
      "59 1.78033\n",
      "60 0.685096\n",
      "61 1.10113\n",
      "62 1.4121\n",
      "63 1.29087\n",
      "64 1.201\n",
      "65 1.46571\n",
      "66 1.00705\n",
      "67 1.62961\n",
      "68 0.82471\n",
      "69 1.77726\n",
      "70 0.684441\n",
      "71 1.11229\n",
      "72 1.39601\n",
      "73 1.30159\n",
      "74 1.18549\n",
      "75 1.47612\n",
      "76 0.991925\n",
      "77 1.6398\n",
      "78 0.809989\n",
      "79 1.78255\n",
      "80 0.680875\n",
      "81 0.9855\n",
      "82 1.53624\n",
      "83 1.18109\n",
      "84 1.31787\n",
      "85 1.36039\n",
      "86 1.11907\n",
      "87 1.52763\n",
      "88 0.933195\n",
      "89 1.68588\n",
      "90 0.757954\n",
      "91 1.77314\n",
      "92 0.682756\n",
      "93 1.10568\n",
      "94 1.39686\n",
      "95 1.29534\n",
      "96 1.18598\n",
      "97 1.4702\n",
      "98 0.992144\n",
      "99 1.63416\n",
      "100 0.810017\n",
      "101 1.77713\n",
      "102 0.680074\n",
      "103 1.01432\n",
      "104 1.4976\n",
      "105 1.20836\n",
      "106 1.28129\n",
      "107 1.38654\n",
      "108 1.08381\n",
      "109 1.55301\n",
      "110 0.898839\n",
      "111 1.71015\n",
      "112 0.72758\n",
      "113 1.69357\n",
      "114 0.74061\n",
      "115 1.73564\n",
      "116 0.700465\n",
      "117 1.47933\n",
      "118 0.97074\n",
      "119 1.65245\n",
      "120 0.779818\n",
      "121 1.77978\n",
      "122 0.677373\n",
      "123 0.841799\n",
      "124 1.68706\n",
      "125 1.04876\n",
      "126 1.45571\n",
      "127 1.23559\n",
      "128 1.24832\n",
      "129 1.40848\n",
      "130 1.05664\n",
      "131 1.57118\n",
      "132 0.875515\n",
      "133 1.72474\n",
      "134 0.711212\n",
      "135 1.59196\n",
      "136 0.845917\n",
      "137 1.74904\n",
      "138 0.689411\n",
      "139 1.30698\n",
      "140 1.15972\n",
      "141 1.4878\n",
      "142 0.959415\n",
      "143 1.65603\n",
      "144 0.773877\n",
      "145 1.77214\n",
      "146 0.678044\n",
      "147 0.951467\n",
      "148 1.55955\n",
      "149 1.15037\n",
      "150 1.337\n",
      "151 1.33233\n",
      "152 1.13534\n",
      "153 1.50166\n",
      "154 0.947495\n",
      "155 1.6616\n",
      "156 0.770365\n",
      "157 1.7672\n",
      "158 0.67976\n",
      "159 1.05771\n",
      "160 1.43779\n",
      "161 1.24908\n",
      "162 1.22491\n",
      "163 1.4254\n",
      "164 1.02962\n",
      "165 1.59059\n",
      "166 0.846182\n",
      "167 1.74291\n",
      "168 0.69233\n",
      "169 1.36188\n",
      "170 1.09487\n",
      "171 1.53743\n",
      "172 0.900499\n",
      "173 1.70107\n",
      "174 0.724176\n",
      "175 1.65503\n",
      "176 0.768524\n",
      "177 1.76204\n",
      "178 0.679854\n",
      "179 1.02816\n",
      "180 1.46754\n",
      "181 1.22448\n",
      "182 1.24836\n",
      "183 1.40454\n",
      "184 1.04892\n",
      "185 1.5725\n",
      "186 0.862649\n",
      "187 1.72858\n",
      "188 0.700832\n",
      "189 1.46981\n",
      "190 0.971854\n",
      "191 1.63994\n",
      "192 0.784194\n",
      "193 1.76565\n",
      "194 0.678439\n",
      "195 0.977115\n",
      "196 1.52387\n",
      "197 1.17471\n",
      "198 1.30303\n",
      "199 1.3558\n",
      "200 1.10241\n",
      "201 1.52457\n",
      "202 0.91523\n",
      "203 1.68373\n",
      "204 0.741124\n",
      "205 1.71056\n",
      "206 0.713334\n",
      "207 1.57597\n",
      "208 0.851421\n",
      "209 1.73685\n",
      "210 0.691573\n",
      "211 1.31919\n",
      "212 1.13581\n",
      "213 1.50055\n",
      "214 0.934956\n",
      "215 1.66907\n",
      "216 0.750756\n",
      "217 1.72892\n",
      "218 0.696255\n",
      "219 1.38808\n",
      "220 1.05771\n",
      "221 1.56629\n",
      "222 0.860539\n",
      "223 1.72911\n",
      "224 0.696004\n",
      "225 1.38261\n",
      "226 1.06342\n",
      "227 1.56088\n",
      "228 0.866154\n",
      "229 1.72432\n",
      "230 0.699239\n",
      "231 1.42398\n",
      "232 1.01675\n",
      "233 1.59995\n",
      "234 0.822277\n",
      "235 1.75256\n",
      "236 0.682393\n",
      "237 1.09853\n",
      "238 1.3821\n",
      "239 1.29099\n",
      "240 1.16786\n",
      "241 1.46825\n",
      "242 0.97161\n",
      "243 1.6341\n",
      "244 0.788355\n",
      "245 1.75773\n",
      "246 0.680908\n",
      "247 1.06396\n",
      "248 1.42117\n",
      "249 1.25572\n",
      "250 1.20782\n",
      "251 1.43249\n",
      "252 1.01207\n",
      "253 1.59812\n",
      "254 0.828409\n",
      "255 1.74536\n",
      "256 0.687193\n",
      "257 1.22766\n",
      "258 1.23644\n",
      "259 1.41016\n",
      "260 1.03424\n",
      "261 1.58001\n",
      "262 0.846145\n",
      "263 1.73439\n",
      "264 0.693\n",
      "265 1.32642\n",
      "266 1.12474\n",
      "267 1.50486\n",
      "268 0.9272\n",
      "269 1.67117\n",
      "270 0.746068\n",
      "271 1.7044\n",
      "272 0.713562\n",
      "273 1.54795\n",
      "274 0.875907\n",
      "275 1.71444\n",
      "276 0.704487\n",
      "277 1.46158\n",
      "278 0.971078\n",
      "279 1.63631\n",
      "280 0.778967\n",
      "281 1.7501\n",
      "282 0.682828\n",
      "283 1.07988\n",
      "284 1.4\n",
      "285 1.27388\n",
      "286 1.18378\n",
      "287 1.45239\n",
      "288 0.986126\n",
      "289 1.61925\n",
      "290 0.801623\n",
      "291 1.75235\n",
      "292 0.682936\n",
      "293 1.10058\n",
      "294 1.37704\n",
      "295 1.29031\n",
      "296 1.16619\n",
      "297 1.46562\n",
      "298 0.972061\n",
      "299 1.63013\n",
      "300 0.790236\n",
      "301 1.75073\n",
      "302 0.68381\n",
      "303 1.12079\n",
      "304 1.35388\n",
      "305 1.3091\n",
      "306 1.14476\n",
      "307 1.48336\n",
      "308 0.951783\n",
      "309 1.64697\n",
      "310 0.771612\n",
      "311 1.73947\n",
      "312 0.689292\n",
      "313 1.23734\n",
      "314 1.22203\n",
      "315 1.42029\n",
      "316 1.0193\n",
      "317 1.59051\n",
      "318 0.830955\n",
      "319 1.74017\n",
      "320 0.6887\n",
      "321 1.22034\n",
      "322 1.24066\n",
      "323 1.40442\n",
      "324 1.0366\n",
      "325 1.57552\n",
      "326 0.847222\n",
      "327 1.73008\n",
      "328 0.694704\n",
      "329 1.3223\n",
      "330 1.126\n",
      "331 1.50113\n",
      "332 0.928004\n",
      "333 1.66774\n",
      "334 0.746933\n",
      "335 1.69158\n",
      "336 0.722921\n",
      "337 1.5895\n",
      "338 0.827018\n",
      "339 1.74272\n",
      "340 0.686131\n",
      "341 1.13855\n",
      "342 1.33104\n",
      "343 1.32943\n",
      "344 1.11873\n",
      "345 1.50565\n",
      "346 0.923649\n",
      "347 1.67026\n",
      "348 0.744907\n",
      "349 1.68335\n",
      "350 0.730627\n",
      "351 1.62763\n",
      "352 0.785596\n",
      "353 1.74442\n",
      "354 0.68539\n",
      "355 1.11371\n",
      "356 1.35871\n",
      "357 1.30566\n",
      "358 1.14504\n",
      "359 1.48273\n",
      "360 0.948998\n",
      "361 1.64836\n",
      "362 0.767254\n",
      "363 1.72716\n",
      "364 0.695928\n",
      "365 1.32476\n",
      "366 1.12167\n",
      "367 1.50409\n",
      "368 0.923121\n",
      "369 1.67093\n",
      "370 0.74259\n",
      "371 1.67124\n",
      "372 0.740854\n",
      "373 1.66413\n",
      "374 0.746748\n",
      "375 1.68223\n",
      "376 0.728833\n",
      "377 1.60998\n",
      "378 0.801979\n",
      "379 1.74678\n",
      "380 0.684131\n",
      "381 1.05747\n",
      "382 1.42142\n",
      "383 1.25321\n",
      "384 1.20287\n",
      "385 1.43318\n",
      "386 1.00354\n",
      "387 1.60126\n",
      "388 0.817621\n",
      "389 1.74175\n",
      "390 0.688005\n",
      "391 1.17781\n",
      "392 1.28647\n",
      "393 1.36345\n",
      "394 1.08053\n",
      "395 1.5358\n",
      "396 0.889663\n",
      "397 1.69618\n",
      "398 0.720342\n",
      "399 1.56052\n",
      "400 0.85911\n",
      "401 1.72039\n",
      "402 0.699703\n",
      "403 1.36199\n",
      "404 1.07852\n",
      "405 1.54026\n",
      "406 0.881215\n",
      "407 1.70418\n",
      "408 0.711623\n",
      "409 1.48825\n",
      "410 0.937408\n",
      "411 1.65953\n",
      "412 0.75142\n",
      "413 1.68934\n",
      "414 0.722567\n",
      "415 1.56615\n",
      "416 0.849614\n",
      "417 1.72775\n",
      "418 0.693803\n",
      "419 1.26138\n",
      "420 1.1901\n",
      "421 1.44683\n",
      "422 0.984391\n",
      "423 1.6189\n",
      "424 0.794844\n",
      "425 1.74161\n",
      "426 0.687301\n",
      "427 1.13846\n",
      "428 1.32931\n",
      "429 1.32794\n",
      "430 1.11868\n",
      "431 1.5032\n",
      "432 0.924617\n",
      "433 1.66712\n",
      "434 0.746811\n",
      "435 1.67469\n",
      "436 0.737692\n",
      "437 1.64167\n",
      "438 0.769215\n",
      "439 1.72093\n",
      "440 0.69836\n",
      "441 1.32845\n",
      "442 1.11459\n",
      "443 1.50988\n",
      "444 0.913629\n",
      "445 1.67793\n",
      "446 0.73383\n",
      "447 1.62304\n",
      "448 0.788091\n",
      "449 1.73773\n",
      "450 0.688717\n",
      "451 1.15495\n",
      "452 1.30978\n",
      "453 1.34498\n",
      "454 1.09846\n",
      "455 1.52067\n",
      "456 0.903957\n",
      "457 1.68414\n",
      "458 0.729704\n",
      "459 1.60274\n",
      "460 0.811114\n",
      "461 1.74084\n",
      "462 0.68769\n",
      "463 1.13378\n",
      "464 1.33388\n",
      "465 1.32369\n",
      "466 1.1227\n",
      "467 1.49932\n",
      "468 0.928221\n",
      "469 1.66358\n",
      "470 0.749853\n",
      "471 1.67883\n",
      "472 0.733498\n",
      "473 1.61802\n",
      "474 0.793673\n",
      "475 1.73843\n",
      "476 0.68865\n",
      "477 1.1476\n",
      "478 1.31783\n",
      "479 1.33748\n",
      "480 1.10669\n",
      "481 1.51307\n",
      "482 0.912267\n",
      "483 1.67681\n",
      "484 0.736517\n",
      "485 1.63062\n",
      "486 0.781104\n",
      "487 1.73009\n",
      "488 0.693296\n",
      "489 1.23903\n",
      "490 1.21473\n",
      "491 1.42395\n",
      "492 1.00963\n",
      "493 1.59575\n",
      "494 0.819829\n",
      "495 1.73732\n",
      "496 0.690007\n",
      "497 1.17961\n",
      "498 1.28206\n",
      "499 1.36618\n",
      "500 1.07497\n",
      "501 1.53929\n",
      "502 0.883282\n",
      "503 1.6994\n",
      "504 0.716542\n",
      "505 1.51186\n",
      "506 0.910847\n",
      "507 1.67902\n",
      "508 0.732605\n",
      "509 1.60795\n",
      "510 0.803671\n",
      "511 1.739\n",
      "512 0.688471\n",
      "513 1.13144\n",
      "514 1.33556\n",
      "515 1.32222\n",
      "516 1.12328\n",
      "517 1.49854\n",
      "518 0.928039\n",
      "519 1.66326\n",
      "520 0.749448\n",
      "521 1.67193\n",
      "522 0.739417\n",
      "523 1.63653\n",
      "524 0.773429\n",
      "525 1.71935\n",
      "526 0.699399\n",
      "527 1.32244\n",
      "528 1.12011\n",
      "529 1.5041\n",
      "530 0.918837\n",
      "531 1.67245\n",
      "532 0.738346\n",
      "533 1.63084\n",
      "534 0.778885\n",
      "535 1.72506\n",
      "536 0.695757\n",
      "537 1.26523\n",
      "538 1.18421\n",
      "539 1.44992\n",
      "540 0.979361\n",
      "541 1.62147\n",
      "542 0.790645\n",
      "543 1.73338\n",
      "544 0.691808\n",
      "545 1.20043\n",
      "546 1.25773\n",
      "547 1.38677\n",
      "548 1.05089\n",
      "549 1.55972\n",
      "550 0.859474\n",
      "551 1.71617\n",
      "552 0.703281\n",
      "553 1.376\n",
      "554 1.06133\n",
      "555 1.5521\n",
      "556 0.866465\n",
      "557 1.71199\n",
      "558 0.705589\n",
      "559 1.39925\n",
      "560 1.03475\n",
      "561 1.57509\n",
      "562 0.840338\n",
      "563 1.72815\n",
      "564 0.694762\n",
      "565 1.24892\n",
      "566 1.20294\n",
      "567 1.43288\n",
      "568 0.998932\n",
      "569 1.60399\n",
      "570 0.810098\n",
      "571 1.7364\n",
      "572 0.690695\n",
      "573 1.17545\n",
      "574 1.28593\n",
      "575 1.36218\n",
      "576 1.0786\n",
      "577 1.53548\n",
      "578 0.886713\n",
      "579 1.69584\n",
      "580 0.719311\n",
      "581 1.52166\n",
      "582 0.899229\n",
      "583 1.6875\n",
      "584 0.724729\n",
      "585 1.55512\n",
      "586 0.86078\n",
      "587 1.71651\n",
      "588 0.701514\n",
      "589 1.3411\n",
      "590 1.09876\n",
      "591 1.52142\n",
      "592 0.899039\n",
      "593 1.68779\n",
      "594 0.724207\n",
      "595 1.55056\n",
      "596 0.865546\n",
      "597 1.71335\n",
      "598 0.703559\n",
      "599 1.36525\n",
      "600 1.07154\n",
      "601 1.5445\n",
      "602 0.873108\n",
      "603 1.7075\n",
      "604 0.70817\n",
      "605 1.41816\n",
      "606 1.01267\n",
      "607 1.59397\n",
      "608 0.818606\n",
      "609 1.73525\n",
      "610 0.690792\n",
      "611 1.16425\n",
      "612 1.29777\n",
      "613 1.35284\n",
      "614 1.08816\n",
      "615 1.52755\n",
      "616 0.894716\n",
      "617 1.68953\n",
      "618 0.724312\n",
      "619 1.55128\n",
      "620 0.86595\n",
      "621 1.71205\n",
      "622 0.705127\n",
      "623 1.38347\n",
      "624 1.05152\n",
      "625 1.56073\n",
      "626 0.855422\n",
      "627 1.71886\n",
      "628 0.700483\n",
      "629 1.32469\n",
      "630 1.11728\n",
      "631 1.50499\n",
      "632 0.917566\n",
      "633 1.67224\n",
      "634 0.738537\n",
      "635 1.62261\n",
      "636 0.787187\n",
      "637 1.72759\n",
      "638 0.694668\n",
      "639 1.23079\n",
      "640 1.22232\n",
      "641 1.41673\n",
      "642 1.01593\n",
      "643 1.58938\n",
      "644 0.825179\n",
      "645 1.7324\n",
      "646 0.692914\n",
      "647 1.2059\n",
      "648 1.25105\n",
      "649 1.3912\n",
      "650 1.04543\n",
      "651 1.56342\n",
      "652 0.854819\n",
      "653 1.71778\n",
      "654 0.702326\n",
      "655 1.35024\n",
      "656 1.08943\n",
      "657 1.52744\n",
      "658 0.893239\n",
      "659 1.69105\n",
      "660 0.722125\n",
      "661 1.53192\n",
      "662 0.886429\n",
      "663 1.6973\n",
      "664 0.71588\n",
      "665 1.48265\n",
      "666 0.940239\n",
      "667 1.65467\n",
      "668 0.753944\n",
      "669 1.67257\n",
      "670 0.736134\n",
      "671 1.60754\n",
      "672 0.801478\n",
      "673 1.73393\n",
      "674 0.690991\n",
      "675 1.15042\n",
      "676 1.31248\n",
      "677 1.34121\n",
      "678 1.10012\n",
      "679 1.5176\n",
      "680 0.904806\n",
      "681 1.68139\n",
      "682 0.73102\n",
      "683 1.58481\n",
      "684 0.828477\n",
      "685 1.73138\n",
      "686 0.69306\n",
      "687 1.19964\n",
      "688 1.25748\n",
      "689 1.38621\n",
      "690 1.05032\n",
      "691 1.5594\n",
      "692 0.858648\n",
      "693 1.71521\n",
      "694 0.703918\n",
      "695 1.36549\n",
      "696 1.07204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 1.54214\n",
      "698 0.876496\n",
      "699 1.70353\n",
      "700 0.711839\n",
      "701 1.44666\n",
      "702 0.980889\n",
      "703 1.6198\n",
      "704 0.790596\n",
      "705 1.72784\n",
      "706 0.694905\n",
      "707 1.22906\n",
      "708 1.22411\n",
      "709 1.41448\n",
      "710 1.01835\n",
      "711 1.58676\n",
      "712 0.827955\n",
      "713 1.73049\n",
      "714 0.694166\n",
      "715 1.22101\n",
      "716 1.23376\n",
      "717 1.40534\n",
      "718 1.02928\n",
      "719 1.57684\n",
      "720 0.839575\n",
      "721 1.72549\n",
      "722 0.697383\n",
      "723 1.27453\n",
      "724 1.17384\n",
      "725 1.45564\n",
      "726 0.973136\n",
      "727 1.62453\n",
      "728 0.787472\n",
      "729 1.72474\n",
      "730 0.697434\n",
      "731 1.27199\n",
      "732 1.1763\n",
      "733 1.45396\n",
      "734 0.974599\n",
      "735 1.6235\n",
      "736 0.788233\n",
      "737 1.7251\n",
      "738 0.697125\n",
      "739 1.26569\n",
      "740 1.18325\n",
      "741 1.44816\n",
      "742 0.980963\n",
      "743 1.61812\n",
      "744 0.793915\n",
      "745 1.72839\n",
      "746 0.695271\n",
      "747 1.23502\n",
      "748 1.21773\n",
      "749 1.41891\n",
      "750 1.01376\n",
      "751 1.59006\n",
      "752 0.824624\n",
      "753 1.73069\n",
      "754 0.694293\n",
      "755 1.21925\n",
      "756 1.23568\n",
      "757 1.40334\n",
      "758 1.03147\n",
      "759 1.57469\n",
      "760 0.841906\n",
      "761 1.72388\n",
      "762 0.698501\n",
      "763 1.28702\n",
      "764 1.1597\n",
      "765 1.46737\n",
      "766 0.959858\n",
      "767 1.63559\n",
      "768 0.775621\n",
      "769 1.71146\n",
      "770 0.705964\n",
      "771 1.3795\n",
      "772 1.05549\n",
      "773 1.55633\n",
      "774 0.859824\n",
      "775 1.71464\n",
      "776 0.703553\n",
      "777 1.34968\n",
      "778 1.08865\n",
      "779 1.52839\n",
      "780 0.890753\n",
      "781 1.69272\n",
      "782 0.720095\n",
      "783 1.50781\n",
      "784 0.912182\n",
      "785 1.67674\n",
      "786 0.733035\n",
      "787 1.58637\n",
      "788 0.824682\n",
      "789 1.73169\n",
      "790 0.692607\n",
      "791 1.17319\n",
      "792 1.28642\n",
      "793 1.36216\n",
      "794 1.07632\n",
      "795 1.53719\n",
      "796 0.882535\n",
      "797 1.69802\n",
      "798 0.716686\n",
      "799 1.48264\n",
      "800 0.940867\n",
      "801 1.65263\n",
      "802 0.756568\n",
      "803 1.67423\n",
      "804 0.735041\n",
      "805 1.59562\n",
      "806 0.814369\n",
      "807 1.73294\n",
      "808 0.691918\n",
      "809 1.15749\n",
      "810 1.30405\n",
      "811 1.34738\n",
      "812 1.09279\n",
      "813 1.52312\n",
      "814 0.898187\n",
      "815 1.68592\n",
      "816 0.726875\n",
      "817 1.55364\n",
      "818 0.862193\n",
      "819 1.71316\n",
      "820 0.704328\n",
      "821 1.35641\n",
      "822 1.08079\n",
      "823 1.5351\n",
      "824 0.882942\n",
      "825 1.69857\n",
      "826 0.715192\n",
      "827 1.4671\n",
      "828 0.957227\n",
      "829 1.63952\n",
      "830 0.769117\n",
      "831 1.70034\n",
      "832 0.712861\n",
      "833 1.44374\n",
      "834 0.982467\n",
      "835 1.61894\n",
      "836 0.790016\n",
      "837 1.72492\n",
      "838 0.696326\n",
      "839 1.23919\n",
      "840 1.21188\n",
      "841 1.42483\n",
      "842 1.00583\n",
      "843 1.59726\n",
      "844 0.815518\n",
      "845 1.73163\n",
      "846 0.693486\n",
      "847 1.19648\n",
      "848 1.26071\n",
      "849 1.38236\n",
      "850 1.05436\n",
      "851 1.55507\n",
      "852 0.863161\n",
      "853 1.71113\n",
      "854 0.706981\n",
      "855 1.39\n",
      "856 1.04417\n",
      "857 1.56506\n",
      "858 0.850529\n",
      "859 1.71948\n",
      "860 0.700615\n",
      "861 1.3088\n",
      "862 1.13441\n",
      "863 1.48913\n",
      "864 0.934598\n",
      "865 1.6569\n",
      "866 0.753089\n",
      "867 1.66368\n",
      "868 0.745289\n",
      "869 1.63771\n",
      "870 0.770057\n",
      "871 1.70112\n",
      "872 0.711836\n",
      "873 1.4313\n",
      "874 0.9959\n",
      "875 1.60781\n",
      "876 0.801548\n",
      "877 1.73037\n",
      "878 0.69335\n",
      "879 1.1843\n",
      "880 1.27366\n",
      "881 1.37261\n",
      "882 1.06435\n",
      "883 1.54715\n",
      "884 0.871141\n",
      "885 1.70596\n",
      "886 0.710389\n",
      "887 1.42358\n",
      "888 1.00634\n",
      "889 1.59731\n",
      "890 0.814658\n",
      "891 1.73151\n",
      "892 0.693353\n",
      "893 1.18981\n",
      "894 1.26792\n",
      "895 1.37647\n",
      "896 1.06062\n",
      "897 1.54978\n",
      "898 0.86875\n",
      "899 1.70728\n",
      "900 0.70969\n",
      "901 1.41661\n",
      "902 1.0143\n",
      "903 1.59032\n",
      "904 0.822478\n",
      "905 1.7304\n",
      "906 0.694068\n",
      "907 1.2029\n",
      "908 1.25322\n",
      "909 1.38869\n",
      "910 1.04696\n",
      "911 1.56134\n",
      "912 0.855878\n",
      "913 1.71553\n",
      "914 0.703815\n",
      "915 1.3506\n",
      "916 1.08796\n",
      "917 1.52782\n",
      "918 0.891719\n",
      "919 1.6911\n",
      "920 0.721756\n",
      "921 1.51595\n",
      "922 0.903111\n",
      "923 1.68327\n",
      "924 0.727312\n",
      "925 1.55059\n",
      "926 0.86382\n",
      "927 1.71247\n",
      "928 0.704122\n",
      "929 1.34661\n",
      "930 1.09092\n",
      "931 1.52686\n",
      "932 0.891261\n",
      "933 1.69228\n",
      "934 0.719862\n",
      "935 1.50048\n",
      "936 0.919523\n",
      "937 1.67062\n",
      "938 0.738137\n",
      "939 1.60682\n",
      "940 0.801934\n",
      "941 1.73002\n",
      "942 0.693401\n",
      "943 1.18057\n",
      "944 1.27758\n",
      "945 1.36942\n",
      "946 1.06759\n",
      "947 1.54438\n",
      "948 0.873908\n",
      "949 1.70388\n",
      "950 0.711847\n",
      "951 1.43551\n",
      "952 0.992817\n",
      "953 1.60865\n",
      "954 0.802131\n",
      "955 1.72948\n",
      "956 0.694354\n",
      "957 1.20493\n",
      "958 1.25063\n",
      "959 1.39105\n",
      "960 1.04399\n",
      "961 1.56394\n",
      "962 0.852664\n",
      "963 1.71736\n",
      "964 0.702459\n",
      "965 1.33216\n",
      "966 1.10839\n",
      "967 1.51048\n",
      "968 0.910883\n",
      "969 1.67589\n",
      "970 0.735035\n",
      "971 1.59336\n",
      "972 0.81782\n",
      "973 1.73105\n",
      "974 0.693347\n",
      "975 1.18352\n",
      "976 1.27458\n",
      "977 1.37108\n",
      "978 1.06617\n",
      "979 1.54508\n",
      "980 0.873521\n",
      "981 1.70382\n",
      "982 0.712137\n",
      "983 1.43765\n",
      "984 0.990561\n",
      "985 1.61031\n",
      "986 0.800443\n",
      "987 1.72857\n",
      "988 0.694918\n",
      "989 1.21379\n",
      "990 1.24061\n",
      "991 1.39937\n",
      "992 1.03461\n",
      "993 1.57185\n",
      "994 0.843807\n",
      "995 1.72196\n",
      "996 0.699483\n",
      "997 1.29024\n",
      "998 1.15525\n",
      "999 1.47073\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "\n",
    "# This is a one-time operation which ensures the parameters get initialized as\n",
    "# we described in the graph: random weights for the matrix, zeros for the biases. \n",
    "tf.global_variables_initializer().run()\n",
    "print(\"Initialized\")\n",
    "\n",
    "for iter in range(1000):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the cost value and the training predictions returned as numpy arrays.\n",
    "    _, J, A = session.run([optimizer, tf_J, tf_A])\n",
    "    \n",
    "    print(iter, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set is  0.584755339586\n",
      "Accuracy on the test set is  0.593806509946\n"
     ]
    }
   ],
   "source": [
    "# Calling .eval() is basically like calling run(), but\n",
    "# just to get that one numpy array. \n",
    "# Note that it recomputes all its computation graph dependencies.\n",
    "A = tf_A.eval()\n",
    "A_test = tf_A_test.eval()\n",
    "\n",
    "print(\"Accuracy on the train set is \", accuracy(A,Y))\n",
    "print(\"Accuracy on the test set is \", accuracy(A_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network in TensorFlow\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('master_normalized.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = prepare(data)\n",
    "\n",
    "X,Y,X_test,Y_test = split_train_test(X,y,pct=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>awayID</th>\n",
       "      <th>homeID</th>\n",
       "      <th>away_goalsPerGame</th>\n",
       "      <th>away_goalsAgainstPerGame</th>\n",
       "      <th>away_evGGARatio</th>\n",
       "      <th>away_powerPlayPercentage</th>\n",
       "      <th>away_penaltyKillPercentage</th>\n",
       "      <th>away_shootingPctg</th>\n",
       "      <th>away_savePctg</th>\n",
       "      <th>away_PDO</th>\n",
       "      <th>home_goalsPerGame</th>\n",
       "      <th>home_goalsAgainstPerGame</th>\n",
       "      <th>home_evGGARatio</th>\n",
       "      <th>home_powerPlayPercentage</th>\n",
       "      <th>home_penaltyKillPercentage</th>\n",
       "      <th>home_shootingPctg</th>\n",
       "      <th>home_savePctg</th>\n",
       "      <th>home_PDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0.803099</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.574564</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.620057</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>0.734781</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.464170</td>\n",
       "      <td>0.613302</td>\n",
       "      <td>0.795786</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.330536</td>\n",
       "      <td>0.584687</td>\n",
       "      <td>0.664542</td>\n",
       "      <td>0.248120</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.393802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559070</td>\n",
       "      <td>0.508894</td>\n",
       "      <td>0.767300</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.566817</td>\n",
       "      <td>0.216551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>0.668819</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>0.849896</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.490333</td>\n",
       "      <td>0.444459</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner  awayID  homeID  away_goalsPerGame  away_goalsAgainstPerGame  \\\n",
       "0       0      21      25           0.803099                  0.075019   \n",
       "1       0       9       6           0.834087                  0.197989   \n",
       "2       1      16       7           0.330536                  0.584687   \n",
       "3       1      23       4           0.559070                  0.508894   \n",
       "4       0      17      20           0.668819                  0.169374   \n",
       "\n",
       "   away_evGGARatio  away_powerPlayPercentage  away_penaltyKillPercentage  \\\n",
       "0         0.789802                  0.932331                    0.475248   \n",
       "1         0.734781                  0.676692                    0.841584   \n",
       "2         0.664542                  0.248120                    0.594059   \n",
       "3         0.767300                  0.563910                    0.287129   \n",
       "4         0.849896                  0.939850                    0.772277   \n",
       "\n",
       "   away_shootingPctg  away_savePctg  away_PDO  home_goalsPerGame  \\\n",
       "0           0.885714       0.700000     1.020           0.574564   \n",
       "1           0.828571       0.733333     1.019           0.464170   \n",
       "2           0.428571       0.066667     0.985           0.393802   \n",
       "3           0.457143       0.066667     0.986           0.566817   \n",
       "4           0.371429       0.766667     1.004           0.227889   \n",
       "\n",
       "   home_goalsAgainstPerGame  home_evGGARatio  home_powerPlayPercentage  \\\n",
       "0                  0.027842         0.620057                  0.751880   \n",
       "1                  0.613302         0.795786                  0.511278   \n",
       "2                  0.000000         0.502732                  0.488722   \n",
       "3                  0.216551         1.000000                  0.458647   \n",
       "4                  0.490333         0.444459                  0.398496   \n",
       "\n",
       "   home_penaltyKillPercentage  home_shootingPctg  home_savePctg  home_PDO  \n",
       "0                    0.821782           0.942857       0.733333     1.023  \n",
       "1                    0.475248           0.400000       0.000000     0.982  \n",
       "2                    1.000000           0.485714       1.000000     1.015  \n",
       "3                    0.445545           0.457143       0.566667     1.001  \n",
       "4                    0.188119           0.171429       0.266667     0.982  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data.\n",
    "n_x = X.shape[1]\n",
    "\n",
    "num_hidden_nodes = 15\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "C = 1\n",
    "\n",
    "# Load the training and test data into constants\n",
    "tf_X = tf.constant(X.astype(np.float32))\n",
    "tf_Y = tf.constant(Y.astype(np.float32))\n",
    "tf_X_test = tf.constant(X_test.astype(np.float32))\n",
    "tf_Y_test = tf.constant(Y_test.astype(np.float32))\n",
    "\n",
    "# Variables.\n",
    "# These are the parameters that we are going to be training.\n",
    "tf_w1 = tf.Variable(tf.truncated_normal((n_x, num_hidden_nodes)))\n",
    "tf_b1 = tf.Variable(tf.zeros((1, num_hidden_nodes)))\n",
    "tf_w2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, C]))\n",
    "tf_b2 = tf.Variable(tf.zeros((1, C)))\n",
    "\n",
    "\n",
    "\n",
    "tf_Z1 = tf.matmul(tf_X, tf_w1) + tf_b1\n",
    "tf_A1 = tf.nn.relu(tf_Z1)    #tf.nn.relu(tf_Z1)\n",
    "tf_Z2 = tf.matmul(tf_A1, tf_w2) + tf_b2\n",
    "tf_A2 = tf.nn.relu(tf_Z2)\n",
    "\n",
    "# Training computation.\n",
    "# We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "# the sigmoid and cross-entropy (it's one operation in TensorFlow, because\n",
    "# it's very common, and it can be optimized). We take the average of this\n",
    "# cross-entropy across all training examples: that's our cost.\n",
    "tf_J = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_Y, logits=tf_Z2) )\n",
    "\n",
    "# Optimizer.\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(tf_J)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(tf_J)\n",
    "\n",
    "\n",
    "# Predictions for the test data.\n",
    "tf_Z1_test = tf.matmul(tf_X_test, tf_w1) + tf_b1\n",
    "tf_A1_test = tf.nn.relu(tf_Z1_test)\n",
    "tf_Z2_test = tf.matmul(tf_A1_test, tf_w2) + tf_b2\n",
    "tf_A2_test = tf.nn.relu(tf_Z2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0 2.59669\n",
      "50 0.776328\n",
      "100 0.723498\n",
      "150 0.700101\n",
      "200 0.685143\n",
      "250 0.67828\n",
      "300 0.67527\n",
      "350 0.675978\n",
      "400 0.667006\n",
      "450 0.679443\n",
      "500 0.671259\n",
      "550 0.665545\n",
      "600 0.665922\n",
      "650 0.665756\n",
      "700 0.66534\n",
      "750 0.665179\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "\n",
    "# This is a one-time operation which ensures the parameters get initialized as\n",
    "# we described in the graph: random weights for the matrix, zeros for the biases. \n",
    "tf.global_variables_initializer().run()\n",
    "print(\"Initialized\")\n",
    "\n",
    "\n",
    "# Replace None with your code.\n",
    "\n",
    "for iter in range(800):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the cost value and the training predictions returned as numpy arrays.\n",
    "    # Print out the iteration number and cost every 50 iterations.\n",
    "    _, J, A = session.run([optimizer, tf_J, tf_A2])\n",
    "    \n",
    "    if iter%50 ==0:\n",
    "        print(iter, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(A, Y):\n",
    "    P = A>.5      #prediction\n",
    "    num_agreements = np.sum(P==Y)\n",
    "    return num_agreements / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set is  0.561758390779\n",
      "Accuracy on the test set is  0.55424954792\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy for the training set and test set.\n",
    "A = tf_A2.eval()\n",
    "A_test = tf_A2_test.eval()\n",
    "\n",
    "print(\"Accuracy on the train set is \", accuracy(A,Y))\n",
    "print(\"Accuracy on the test set is \", accuracy(A_test,Y_test))\n",
    "# Put your code here.\n",
    "\n",
    "# Call .eval() on tf_A2 and tf_A2_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('master_normalized.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = prepare(data)\n",
    "\n",
    "X,Y,X_test,Y_test = split_train_test(X,y,pct=80)\n",
    "\n",
    "n_x = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data.\n",
    "# Let's use placeholders for the training data. \n",
    "# This is so that we can suply batches of tranining examples each iteration.\n",
    "tf_X = tf.placeholder(tf.float32)\n",
    "tf_Y = tf.placeholder(tf.float32)\n",
    "\n",
    "tf_X_test = tf.constant(X_test.astype(np.float32))\n",
    "tf_Y_test = tf.constant(Y_test.astype(np.float32))\n",
    "\n",
    "# Variables.\n",
    "# These are the parameters that we are going to be training.\n",
    "tf_w = tf.Variable( tf.zeros((n_x, 1)) )\n",
    "tf_b = tf.Variable(tf.zeros((1,1)))\n",
    "\n",
    "# Training computation.\n",
    "# We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "# the sigmoid and cross-entropy (it's one operation in TensorFlow, because\n",
    "# it's very common, and it can be optimized). We take the average of this\n",
    "# cross-entropy across all training examples: that's our cost.\n",
    "tf_Z = tf.matmul(tf_X, tf_w) + tf_b\n",
    "tf_J = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_Y, logits=tf_Z) )\n",
    "\n",
    "# Optimizer.\n",
    "# We are going to find the minimum of this loss using gradient descent.\n",
    "# We pass alpha=0.1 as input parameter.\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(tf_J)\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(tf_J)\n",
    "\n",
    "\n",
    "# Predictions for the train and test data.\n",
    "# These are not part of training, but merely here so that we can report\n",
    "# accuracy figures as we train.\n",
    "tf_A = tf.nn.sigmoid(tf_Z)\n",
    "tf_A_test = tf.nn.sigmoid(tf.matmul(tf_X_test, tf_w) + tf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step  (0, 0.69314742)\n",
      "Minibatch accuracy:  0.42\n",
      "Test accuracy:  0.530741410488\n",
      "Minibatch loss at step  (500, 0.67694199)\n",
      "Minibatch accuracy:  0.57\n",
      "Test accuracy:  0.603752260398\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "batch_size = 100\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "print(\"Initialized\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Pick an offset within the training data.\n",
    "    offset = (step * batch_size) % (X.shape[0] - batch_size)\n",
    "    \n",
    "    # Generate a minibatch.\n",
    "    X_batch = X[offset:(offset + batch_size), :]\n",
    "    Y_batch = Y[offset:(offset + batch_size), :]\n",
    "    \n",
    "    _, J, A = session.run([optimizer, tf_J, tf_A], feed_dict={tf_X : X_batch, tf_Y : Y_batch})\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "        print(\"Minibatch loss at step \", (step, J))\n",
    "        print(\"Minibatch accuracy: \", accuracy(A, Y_batch))\n",
    "        A_test = tf_A_test.eval()\n",
    "        print(\"Test accuracy: \", accuracy(A_test,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
